%! Author = sean
%! Date = 26/6/23

@article{lu_survey_nodate,
    title = {A {Survey} of {Deep} {Learning} for {Mathematical} {Reasoning}},
    abstract = {Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various ﬁelds, including science, engineering, ﬁnance, and everyday life. The development of artiﬁcial intelligence (AI) systems capable of solving math problems and proving theorems has garnered signiﬁcant interest in the ﬁelds of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.},
    language = {en},
    author = {Lu, Pan and Qiu, Liang and Yu, Wenhao and Welleck, Sean and Chang, Kai-Wei},
}

@inproceedings{slind_brief_2008,
    address = {Berlin, Heidelberg},
    title = {A {Brief} {Overview} of {HOL4}},
    isbn = {978-3-540-71067-7},
    abstract = {The HOLF proof assistant supports specification and proof in classical higher order logic. It is the latest in a long line of similar systems. In this short overview, we give an outline of the HOLF system and how it may be applied in formal verification.},
    booktitle = {Theorem {Proving} in {Higher} {Order} {Logics}},
    publisher = {Springer Berlin Heidelberg},
    author = {Slind, Konrad and Norrish, Michael},
    editor = {Mohamed, Otmane Ait and Muñoz, César and Tahar, Sofiène},
    year = {2008},
    pages = {28--32},
}

@book{paulson_isabelle_1994,
    address = {Berlin/Heidelberg},
    series = {Lecture {Notes} in {Computer} {Science}},
    title = {Isabelle},
    volume = {828},
    isbn = {978-3-540-58244-1},
    url = {http://link.springer.com/10.1007/BFb0030541},
    language = {en},
    urldate = {2023-06-26},
    publisher = {Springer-Verlag},
    editor = {Paulson, Lawrence C.},
    year = {1994},
    doi = {10.1007/BFb0030541},
    keywords = {Höherstufige Logik, Isabelle, Schließen, Syntax, automated reasoning, automatische Verifikation, computer, documentation, logic, mathematics, proof, sequent calculus, set theory, type theory, verification},
}

@article{kern_formal_2002,
    title = {Formal {Verification} {In} {Hardware} {Design}: {A} {Survey}},
    volume = {4},
    shorttitle = {Formal {Verification} {In} {Hardware} {Design}},
    doi = {10.1145/307988.307989},
    abstract = {In recent years, formal methods have emerged as an alternative approach to ensuring the quality and correctness of hardware designs, overcoming some of the limitations of traditional validation techniques such as simulation and testing.
There are two main aspects to the application of formal methods in a design process: the formal framework used to specify desired properties of a design and the verification techniques and tools used to reason about the relationship between a specification and a corresponding implementation. We survey a variety of frameworks and techniques proposed in the literature and applied to actual designs. The specification frameworks we describe include temporal logics, predicate logic, abstraction and refinement, as well as containment between ω-regular languages. The verification techniques presented include model checking, automata-theoretic techniques, automated theorem proving, and approaches that integrate the above methods.
In order to provide insight into the scope and limitations of currently available techniques, we present a selection of case studies where formal methods were applied to industrial-scale designs, such as microprocessors, floating-point hardware, protocols, memory subsystems, and communications hardware.},
    journal = {ACM Transactions on Design Automation of Electronic Systems},
    author = {Kern, Christoph and Greenstreet, Mark},
    month = dec,
    year = {2002},
}

@inproceedings{franca_formally_2012,
    title = {Formally verified optimizing compilation in {ACG}-based flight control software},
    url = {https://inria.hal.science/hal-00653367},
    abstract = {This work presents an evaluation of the CompCert formally specified and verified optimizing compiler for the development of DO-178 level A flight control software. First, some fundamental characteristics of flight control software are presented and the case study program is described. Then, the use of CompCert is justified: its main point is to allow optimized code generation by relying on the formal proof of correctness and additional compilation information instead of the current un-optimized generation required to produce predictable assembly code patterns. The evaluation of its performance (measured using WCET and code size) is presented and the results are compared to those obtained with the currently used compiler.},
    language = {en},
    urldate = {2023-06-26},
    author = {França, Ricardo Bedin and Blazy, Sandrine and Favre-Felix, Denis and Leroy, Xavier and Pantel, Marc and Souyris, Jean},
    month = feb,
    year = {2012},
}

@article{vanderleest_is_2018,
    title = {Is formal proof of {seL4} sufficient for avionics security?},
    volume = {33},
    issn = {0885-8985},
    url = {https://ieeexplore.ieee.org/document/8332372/},
    doi = {10.1109/MAES.2018.160217},
    number = {2},
    urldate = {2023-06-26},
    journal = {IEEE Aerospace and Electronic Systems Magazine},
    author = {VanderLeest, Steven H.},
    month = feb,
    year = {2018},
    pages = {16--21},
}

@inproceedings{jiang_lisa_2021,
    title = {{LISA}: {Language} models of {ISAbelle} proofs},
    abstract = {We introduce an environment that allows interaction with an Isabelle server in an incremental manner. With this environment, we mined the Isabelle standard library and the Archive of Formal Proofs (AFP) and extracted 183K lemmas and theorems. We built language models on this large corpus and showed their effectiveness in proving AFP theorems.},
    language = {en},
    booktitle = {6th {Conference} on {Artificial} {Intelligence} and {Theorem} {Proving}},
    author = {Jiang, Albert Qiaochu and Li, Wenda and Han, Jesse Michael and Wu, Yuhuai},
    year = {2021},
}

@article{wu_int_2020,
    title = {{INT}: {An} {Inequality} {Benchmark} for {Evaluating} {Generalization} in {Theorem} {Proving}},
    copyright = {arXiv.org perpetual, non-exclusive license},
    shorttitle = {{INT}},
    url = {https://arxiv.org/abs/2007.02924},
    doi = {10.48550/ARXIV.2007.02924},
    abstract = {In learning-assisted theorem proving, one of the most critical challenges is to generalize to theorems unlike those seen at training time. In this paper, we introduce INT, an INequality Theorem proving benchmark, specifically designed to test agents' generalization ability. INT is based on a procedure for generating theorems and proofs; this procedure's knobs allow us to measure 6 different types of generalization, each reflecting a distinct challenge characteristic to automated theorem proving. In addition, unlike prior benchmarks for learning-assisted theorem proving, INT provides a lightweight and user-friendly theorem proving environment with fast simulations, conducive to performing learning-based and search-based research. We introduce learning-based baselines and evaluate them across 6 dimensions of generalization with the benchmark. We then evaluate the same agents augmented with Monte Carlo Tree Search (MCTS) at test time, and show that MCTS can help to prove new theorems.},
    urldate = {2023-06-26},
    author = {Wu, Yuhuai and Jiang, Albert Qiaochu and Ba, Jimmy and Grosse, Roger},
    year = {2020},
    note = {Publisher: arXiv
Version Number: 2},
    keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Logic in Computer Science (cs.LO), Machine Learning (cs.LG), Machine Learning (stat.ML)},
}

@article{grabowski_four_2015,
    title = {Four {Decades} of {Mizar}: {Foreword}},
    volume = {55},
    issn = {0168-7433, 1573-0670},
    shorttitle = {Four {Decades} of {Mizar}},
    url = {http://link.springer.com/10.1007/s10817-015-9345-1},
    doi = {10.1007/s10817-015-9345-1},
    language = {en},
    number = {3},
    urldate = {2023-06-26},
    journal = {Journal of Automated Reasoning},
    author = {Grabowski, Adam and Korniłowicz, Artur and Naumowicz, Adam},
    month = oct,
    year = {2015},
    pages = {191--198},
}

@article{huang_gamepad_2018,
    title = {{GamePad}: {A} {Learning} {Environment} for {Theorem} {Proving}},
    copyright = {arXiv.org perpetual, non-exclusive license},
    shorttitle = {{GamePad}},
    url = {https://arxiv.org/abs/1806.00608},
    doi = {10.48550/ARXIV.1806.00608},
    abstract = {In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.},
    urldate = {2023-06-26},
    author = {Huang, Daniel and Dhariwal, Prafulla and Song, Dawn and Sutskever, Ilya},
    year = {2018},
    note = {Publisher: arXiv
Version Number: 2},
    keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Logic in Computer Science (cs.LO), Machine Learning (cs.LG), Machine Learning (stat.ML)},
}

@article{polu_formal_2022,
    title = {Formal {Mathematics} {Statement} {Curriculum} {Learning}},
    copyright = {arXiv.org perpetual, non-exclusive license},
    url = {https://arxiv.org/abs/2202.01344},
    doi = {10.48550/ARXIV.2202.01344},
    abstract = {We explore the use of expert iteration in the context of language modeling applied to formal mathematics. We show that at same compute budget, expert iteration, by which we mean proof search interleaved with learning, dramatically outperforms proof search only. We also observe that when applied to a collection of formal statements of sufficiently varied difficulty, expert iteration is capable of finding and solving a curriculum of increasingly difficult problems, without the need for associated ground-truth proofs. Finally, by applying this expert iteration to a manually curated set of problem statements, we achieve state-of-the-art on the miniF2F benchmark, automatically solving multiple challenging problems drawn from high school olympiads.},
    urldate = {2023-06-26},
    author = {Polu, Stanislas and Han, Jesse Michael and Zheng, Kunhao and Baksys, Mantas and Babuschkin, Igor and Sutskever, Ilya},
    year = {2022},
    note = {Publisher: arXiv
Version Number: 1},
    keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@article{kaliszyk_holstep_2017,
    title = {{HolStep}: {A} {Machine} {Learning} {Dataset} for {Higher}-order {Logic} {Theorem} {Proving}},
    shorttitle = {{HolStep}},
    url = {https://www.semanticscholar.org/paper/HolStep%3A-A-Machine-Learning-Dataset-for-Logic-Kaliszyk-Chollet/f1318d15d7d8ab626b92d0c70dbdc5b5d37e223f},
    abstract = {Large computer-understandable proofs consist of millions of intermediate logical steps. The vast majority of such steps originate from manually selected and manually guided heuristics applied to intermediate goals. So far, machine learning has generally not been used to filter or generate these steps. In this paper, we introduce a new dataset based on Higher-Order Logic (HOL) proofs, for the purpose of developing new machine learning-based theorem-proving strategies. We make this dataset publicly available under the BSD license. We propose various machine learning tasks that can be performed on this dataset, and discuss their significance for theorem proving. We also benchmark a set of simple baseline machine learning models suited for the tasks (including logistic regression, convolutional neural networks and recurrent neural networks). The results of our baseline models show the promise of applying machine learning to HOL theorem proving.},
    urldate = {2023-06-26},
    journal = {ArXiv},
    author = {Kaliszyk, C. and Chollet, François and Szegedy, Christian},
    month = mar,
    year = {2017},
}

@article{yang_learning_2019,
    title = {Learning to {Prove} {Theorems} via {Interacting} with {Proof} {Assistants}},
    copyright = {arXiv.org perpetual, non-exclusive license},
    url = {https://arxiv.org/abs/1905.09381},
    doi = {10.48550/ARXIV.1905.09381},
    abstract = {Humans prove theorems by relying on substantial high-level reasoning and problem-specific insights. Proof assistants offer a formalism that resembles human mathematical reasoning, representing theorems in higher-order logic and proofs as high-level tactics. However, human experts have to construct proofs manually by entering tactics into the proof assistant. In this paper, we study the problem of using machine learning to automate the interaction with proof assistants. We construct CoqGym, a large-scale dataset and learning environment containing 71K human-written proofs from 123 projects developed with the Coq proof assistant. We develop ASTactic, a deep learning-based model that generates tactics as programs in the form of abstract syntax trees (ASTs). Experiments show that ASTactic trained on CoqGym can generate effective tactics and can be used to prove new theorems not previously provable by automated methods. Code is available at https://github.com/princeton-vl/CoqGym.},
    urldate = {2023-06-26},
    author = {Yang, Kaiyu and Deng, Jia},
    year = {2019},
    note = {Publisher: arXiv
Version Number: 1},
    keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Logic in Computer Science (cs.LO), Machine Learning (cs.LG), Machine Learning (stat.ML)},
}

@article{han_proof_2021,
    title = {Proof {Artifact} {Co}-training for {Theorem} {Proving} with {Language} {Models}},
    copyright = {Creative Commons Attribution Share Alike 4.0 International},
    url = {https://arxiv.org/abs/2102.06203},
    doi = {10.48550/ARXIV.2102.06203},
    abstract = {Labeled data for imitation learning of theorem proving in large libraries of formalized mathematics is scarce as such libraries require years of concentrated effort by human specialists to be built. This is particularly challenging when applying large Transformer language models to tactic prediction, because the scaling of performance with respect to model size is quickly disrupted in the data-scarce, easily-overfitted regime. We propose PACT (\{{\textbackslash}bf P\}roof \{{\textbackslash}bf A\}rtifact \{{\textbackslash}bf C\}o-\{{\textbackslash}bf T\}raining), a general methodology for extracting abundant self-supervised data from kernel-level proof terms for co-training alongside the usual tactic prediction objective. We apply this methodology to Lean, an interactive proof assistant which hosts some of the most sophisticated formalized mathematics to date. We instrument Lean with a neural theorem prover driven by a Transformer language model and show that PACT improves theorem proving success rate on a held-out suite of test theorems from 32{\textbackslash}\% to 48{\textbackslash}\%.},
    urldate = {2023-06-26},
    author = {Han, Jesse Michael and Rute, Jason and Wu, Yuhuai and Ayers, Edward W. and Polu, Stanislas},
    year = {2021},
    note = {Publisher: arXiv
Version Number: 2},
    keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Logic in Computer Science (cs.LO), Machine Learning (cs.LG)},
}

@article{li_isarstep_2020,
    title = {{IsarStep}: a {Benchmark} for {High}-level {Mathematical} {Reasoning}},
    copyright = {arXiv.org perpetual, non-exclusive license},
    shorttitle = {{IsarStep}},
    url = {https://arxiv.org/abs/2006.09265},
    doi = {10.48550/ARXIV.2006.09265},
    abstract = {A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline.},
    urldate = {2023-06-26},
    author = {Li, Wenda and Yu, Lei and Wu, Yuhuai and Paulson, Lawrence C.},
    year = {2020},
    note = {Publisher: arXiv
Version Number: 2},
    keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, I.2.3; I.2.7; F.4.1; F.1.1; I.2.2, Logic in Computer Science (cs.LO), Machine Learning (cs.LG), Machine Learning (stat.ML), Programming Languages (cs.PL)},
}

@article{zheng_minif2f_2021,
    title = {{MiniF2F}: a cross-system benchmark for formal {Olympiad}-level mathematics},
    copyright = {arXiv.org perpetual, non-exclusive license},
    shorttitle = {{MiniF2F}},
    url = {https://arxiv.org/abs/2109.00110},
    doi = {10.48550/ARXIV.2109.00110},
    abstract = {We present miniF2F, a dataset of formal Olympiad-level mathematics problems statements intended to provide a unified cross-system benchmark for neural theorem proving. The miniF2F benchmark currently targets Metamath, Lean, Isabelle (partially) and HOL Light (partially) and consists of 488 problem statements drawn from the AIME, AMC, and the International Mathematical Olympiad (IMO), as well as material from high-school and undergraduate mathematics courses. We report baseline results using GPT-f, a neural theorem prover based on GPT-3 and provide an analysis of its performance. We intend for miniF2F to be a community-driven effort and hope that our benchmark will help spur advances in neural theorem proving.},
    urldate = {2023-06-26},
    author = {Zheng, Kunhao and Han, Jesse Michael and Polu, Stanislas},
    year = {2021},
    note = {Publisher: arXiv
Version Number: 2},
    keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Formal Languages and Automata Theory (cs.FL), Machine Learning (cs.LG)},
}

@misc{bansal_holist_2019,
    title = {{HOList}: {An} {Environment} for {Machine} {Learning} of {Higher}-{Order} {Theorem} {Proving}},
    shorttitle = {{HOList}},
    url = {http://arxiv.org/abs/1904.03241},
    abstract = {We present an environment, benchmark, and deep learning driven automated theorem prover for higher-order logic. Higher-order interactive theorem provers enable the formalization of arbitrary mathematical theories and thereby present an interesting, open-ended challenge for deep learning. We provide an open-source framework based on the HOL Light theorem prover that can be used as a reinforcement learning environment. HOL Light comes with a broad coverage of basic mathematical theorems on calculus and the formal proof of the Kepler conjecture, from which we derive a challenging benchmark for automated reasoning. We also present a deep reinforcement learning driven automated theorem prover, DeepHOL, with strong initial results on this benchmark.},
    language = {en},
    urldate = {2023-04-06},
    publisher = {arXiv},
    author = {Bansal, Kshitij and Loos, Sarah M. and Rabe, Markus N. and Szegedy, Christian and Wilcox, Stewart},
    month = nov,
    year = {2019},
    note = {arXiv:1904.03241 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
}

@misc{jakubuv_mizar_2023,
    title = {{MizAR} 60 for {Mizar} 50},
    url = {http://arxiv.org/abs/2303.06686},
    abstract = {As a present to Mizar on its 50th anniversary, we develop an AI/TP system that automatically proves about 60 \% of the Mizar theorems in the hammer setting. We also automatically prove 75 \% of the Mizar theorems when the automated provers are helped by using only the premises used in the human-written Mizar proofs. We describe the methods and large-scale experiments leading to these results. This includes in particular the E and Vampire provers, their ENIGMA and Deepire learning modiﬁcations, a number of learning-based premise selection methods, and the incremental loop that interleaves growing a corpus of millions of ATP proofs with training increasingly strong AI/TP systems on them. We also present a selection of Mizar problems that were proved automatically.},
    language = {en},
    urldate = {2023-05-02},
    publisher = {arXiv},
    author = {Jakubův, Jan and Chvalovský, Karel and Goertzel, Zarathustra and Kaliszyk, Cezary and Olšák, Mirek and Piotrowski, Bartosz and Schulz, Stephan and Suda, Martin and Urban, Josef},
    month = mar,
    year = {2023},
    note = {arXiv:2303.06686 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Symbolic Computation},
}

@article{heiser_sel4_australia_2020,
    title = {{seL4} in {Australia}: from research to real-world trustworthy systems},
    volume = {63},
    issn = {0001-0782, 1557-7317},
    shorttitle = {{seL4} in {Australia}},
    url = {https://dl.acm.org/doi/10.1145/3378426},
    doi = {10.1145/3378426},
    language = {en},
    number = {4},
    urldate = {2023-06-26},
    journal = {Communications of the ACM},
    author = {Heiser, Gernot and Klein, Gerwin and Andronick, June},
    month = mar,
    year = {2020},
    pages = {72--75},
}

@article{matos_sel4_2022,
    title = {{seL4} {Microkernel} for {Virtualization} {Use}-{Cases}: {Potential} {Directions} towards a {Standard} {VMM}},
    volume = {11},
    issn = {2079-9292},
    shorttitle = {{seL4} {Microkernel} for {Virtualization} {Use}-{Cases}},
    url = {https://www.mdpi.com/2079-9292/11/24/4201},
    doi = {10.3390/electronics11244201},
    abstract = {Virtualization plays an essential role in providing security to computational systems by isolating execution environments. Many software solutions, called hypervisors, have been proposed to provide virtualization capabilities. However, only a few were designed for being deployed at the edge of the network in devices with fewer computation resources when compared with servers in the Cloud. Among the few lightweight software that can play the hypervisor role, seL4 stands out by providing a small Trusted Computing Base and formally verified components, enhancing its security. Despite today being more than a decade with seL4 microkernel technology, its existing userland and tools are still scarce and not very mature. Over the last few years, the main effort has been to increase the maturity of the kernel itself, and not the tools and applications that can be hosted on top. Therefore, it currently lacks proper support for a full-featured userland Virtual Machine Monitor, and the existing one is quite fragmented. This article discusses the potential directions to a standard VMM by presenting our view of design principles and the feature set needed. This article does not intend to define a standard VMM, we intend to instigate this discussion through the seL4 community.},
    language = {en},
    number = {24},
    urldate = {2023-06-26},
    journal = {Electronics},
    author = {Matos, Everton De and Ahvenjärvi, Markku},
    month = dec,
    year = {2022},
    pages = {4201},
}

@misc{noauthor_nasa_nodate,
    title = {{NASA} {Launches} {Space} {Cyber}-resilience into a {New} {Era} with the {seL4} {Microkernel} - {DornerWorks}},
    url = {https://dornerworks.com/blog/sel4-nasa-space-sbir-phase-ii/},
    urldate = {2023-04-05},
}

@inproceedings{heiser_sel4_2020,
    title = {The {seL4} {Microkernel} – {An} {Introduction}},
    url = {https://www.semanticscholar.org/paper/The-seL4-Microkernel-%E2%80%93-An-Introduction-Heiser/829ac81db0e9b1448644576b3115a9cca60265d9},
    abstract = {This whitepaper provides an introduction to and overview of seL4. We explain what seL4 is (and is not) and explore its defining features. We explain what makes seL4 uniquely qualified as the operating-system kernel of choice for securityand safetycritical systems, and generally embedded and cyber-physical systems. In particular, we explain seL4’s assurance story, its securityand safety-relevant features, and its benchmark-setting performance. We also discuss typical usage scenarios, including incremental cyber retrofit of legacy systems. CCS Concepts • Software and its engineering → Operating Systems • Security and privacy → Systems security • Security and privacy → Formal methods and theory of security • Computer systems organization → Real-time systems → Real-time operating systems • Computer systems organization → Real-time systems → Dependable and faulttolerant systems and networks},
    urldate = {2023-06-26},
    author = {Heiser, G.},
    year = {2020},
}

@book{milner_definition_1997,
    title = {The {Definition} of {Standard} {ML}},
    isbn = {978-0-262-28700-5},
    url = {https://direct.mit.edu/books/book/2094/the-definition-of-standard-ml},
    language = {en},
    urldate = {2023-06-26},
    publisher = {The MIT Press},
    author = {Milner, Robin and Harper, Robert and MacQueen, David and Tofte, Mads},
    year = {1997},
    doi = {10.7551/mitpress/2319.001.0001},
}

@article{leroy_compcert_2014,
    title = {The {CompCert} {C} verified compiler: {Documentation} and user’s manual},
    shorttitle = {The {CompCert} {C} verified compiler},
    abstract = {This document is the user’s manual for the CompCert C verified compiler. It is organized as follows: Chapter 1 gives an overview of the CompCert C compiler and of the formal verification of compilers. Chapter 2 explains how to install CompCert C. Chapter 3 explains how to use the CompCert C compiler. Chapter 4 explains how to use the CompCert C reference interpreter. Chapter 5 describes the subset of the ISO C99 language that is implemented by CompCert. Chapter 6 describes the supported language extensions: pragmas, attributes, built-in functions. Chapter 7 describes the experimental tool cchecklink that validates a posteriori the correctness of assembling and linking the code produced by the CompCert C compiler.},
    author = {Leroy, Xavier},
    month = sep,
    year = {2014},
}

@book{megill_metamath_2019,
    title = {Metamath: {A} {Computer} {Language} for {Mathematical} {Proofs}},
    isbn = {978-0-359-70223-7},
    shorttitle = {Metamath},
    abstract = {Metamath is a computer language and an associated computer program for archiving, verifying, and studying mathematical proofs. The Metamath language is simple and robust, with an almost total absence of hard-wired syntax, and we believe that it provides about the simplest possible framework that allows essentially all of mathematics to be expressed with absolute rigor. While simple, it is also powerful; the Metamath Proof Explorer (MPE) database has over 23,000 proven theorems and is one of the top systems in the "Formalizing 100 Theorems" challenge. This book explains the Metamath language and program, with specific emphasis on the fundamentals of the MPE database.},
    language = {en},
    publisher = {Lulu.com},
    author = {Megill, Norman and Wheeler, David A.},
    year = {2019},
    note = {Google-Books-ID: dxqeDwAAQBAJ},
}

@inproceedings{wiedijk_bruijn_2000,
    title = {The {De} {Bruijn} {Factor}},
    url = {https://www.semanticscholar.org/paper/The-De-Bruijn-Factor-Wiedijk/8039ba5de3cc5f23ea3e8ccd4211a8242f18a95e},
    abstract = {We study de Bruijn’s ‘loss factor’ between the size of an ordinary mathematical exposition and its full formal translation inside a computer. This factor is determined by a combination of the amount of detail present in the original text and the expressivity of the system used to do the formalization. For three specific examples this factor turns out to be approximately equal to four.},
    urldate = {2023-06-26},
    author = {Wiedijk, Freek},
    year = {2000},
}

@incollection{harrison_history_2014,
    title = {History of {Interactive} {Theorem} {Proving}},
    volume = {9},
    isbn = {978-0-444-51624-4},
    url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444516244500046},
    language = {en},
    urldate = {2023-06-26},
    booktitle = {Handbook of the {History} of {Logic}},
    publisher = {Elsevier},
    author = {Harrison, John and Urban, Josef and Wiedijk, Freek},
    year = {2014},
    doi = {10.1016/B978-0-444-51624-4.50004-6},
    pages = {135--214},
}

@article{nawaz_survey_2019,
    title = {A {Survey} on {Theorem} {Provers} in {Formal} {Methods}},
    copyright = {arXiv.org perpetual, non-exclusive license},
    url = {https://arxiv.org/abs/1912.03028},
    doi = {10.48550/ARXIV.1912.03028},
    abstract = {Mechanical reasoning is a key area of research that lies at the crossroads of mathematical logic and artificial intelligence. The main aim to develop mechanical reasoning systems (also known as theorem provers) was to enable mathematicians to prove theorems by computer programs. However, these tools evolved with time and now play vital role in the modeling and reasoning about complex and large-scale systems, especially safety-critical systems. Technically, mathematical formalisms and automated reasoning based-approaches are employed to perform inferences and to generate proofs in theorem provers. In literature, there is a shortage of comprehensive documents that can provide proper guidance about the preferences of theorem provers with respect to their designs, performances, logical frameworks, strengths, differences and their application areas. In this work, more than 40 theorem provers are studied in detail and compared to present a comprehensive analysis and evaluation of these tools. Theorem provers are investigated based on various parameters, which includes: implementation architecture, logic and calculus used, library support, level of automation, programming paradigm, programming language, differences and application areas.},
    urldate = {2023-06-26},
    author = {Nawaz, M. Saqib and Malik, Moin and Li, Yi and Sun, Meng and Lali, M. Ikram Ullah},
    year = {2019},
    note = {Publisher: arXiv
Version Number: 1},
    keywords = {FOS: Computer and information sciences, Formal Languages and Automata Theory (cs.FL), Logic in Computer Science (cs.LO), Software Engineering (cs.SE)},
}

@article{gupta_formal_1992,
    title = {Formal hardware verification methods: {A} survey},
    volume = {1},
    issn = {1572-8102},
    shorttitle = {Formal hardware verification methods},
    url = {https://doi.org/10.1007/BF00121125},
    doi = {10.1007/BF00121125},
    abstract = {Growing advances in VLSI technology have led to an increased level of complexity in current hardware systems. Late detection of design errors typically results in higher costs due to the associated time delay as well as loss of production. Thus it is important that hardware designs be free of errors. Formal verification has become an increasingly important technique towards establishing the correctness of hardware designs. In this article we survey the research that has been done in this area, with an emphasis on more recent trends. We present a classification framework for the various methods, based on the forms of the specification, the implementation, and the proff method. This framework enables us to better highlight the relationships and interactions between seemingly different approaches.},
    language = {en},
    number = {2},
    urldate = {2023-06-26},
    journal = {Formal Methods in System Design},
    author = {Gupta, Aarti},
    month = oct,
    year = {1992},
    keywords = {design correctness, formal verification, hardware verification, proof methods, specification},
    pages = {151--238},
}

@inproceedings{gonthier_four_2008,
    address = {Berlin, Heidelberg},
    series = {Lecture {Notes} in {Computer} {Science}},
    title = {The {Four} {Colour} {Theorem}: {Engineering} of a {Formal} {Proof}},
    isbn = {978-3-540-87827-8},
    shorttitle = {The {Four} {Colour} {Theorem}},
    doi = {10.1007/978-3-540-87827-8_28},
    abstract = {The 150 year old Four Colour Theorem is the first famous result with a proof that requires large computer calculations. Such proofs are still controversial: It is thought that computer programs cannot be reviewed with mathematical rigor.},
    language = {en},
    booktitle = {Computer {Mathematics}},
    publisher = {Springer},
    author = {Gonthier, Georges},
    editor = {Kapur, Deepak},
    year = {2008},
    pages = {333--333},
}

@article{hales_formal_2017,
    title = {A {FORMAL} {PROOF} {OF} {THE} {KEPLER} {CONJECTURE}},
    volume = {5},
    issn = {2050-5086},
    url = {https://www.cambridge.org/core/journals/forum-of-mathematics-pi/article/formal-proof-of-the-kepler-conjecture/78FBD5E1A3D1BCCB8E0D5B0C463C9FBC},
    doi = {10.1017/fmp.2017.1},
    abstract = {This article describes a formal proof of the Kepler conjecture on dense sphere packings in a combination of the HOL Light and Isabelle proof assistants. This paper constitutes the official published account of the now completed Flyspeck project.},
    language = {en},
    urldate = {2023-06-26},
    journal = {Forum of Mathematics, Pi},
    author = {Hales, Thomas and Adams, Mark and Bauer, Gertrud and Dang, Tat Dat and Harrison, John and Hoang, Le Truong and Kaliszyk, Cezary and Magron, Victor and Mclaughlin, Sean and Nguyen, Tat Thang and Nguyen, Quang Truong and Nipkow, Tobias and Obua, Steven and Pleso, Joseph and Rute, Jason and Solovyev, Alexey and Ta, Thi Hoai An and Tran, Nam Trung and Trieu, Thi Diep and Urban, Josef and Vu, Ky and Zumkeller, Roland},
    month = jan,
    year = {2017},
    note = {Publisher: Cambridge University Press},
    keywords = {52C17},
    pages = {e2},
}

@inproceedings{moses_no_2017,
    title = {No {More} {Excuses}: {Automated} {Synthesis} of {Practical} and {Verifiable} {Vote}-{Counting} {Programs} for {Complex} {Voting} {Schemes}},
    isbn = {978-3-319-68686-8},
    shorttitle = {No {More} {Excuses}},
    doi = {10.1007/978-3-319-68687-5_5},
    abstract = {We argue that electronic vote-counting software can engender broad-based public trust in elections to public office only if they are formally verified against their legal definition and only if they can produce an easily verifiable certificate for the correctness of the count. We then show that both are achievable for the Schulze method of vote-counting, even when the election involves millions of ballots. We argue that our methodology is applicable to any vote-counting scheme that is rigorously specified. Consequently, the current practice of using unverified and unverifiable vote counting software for elections to public office is untenable. In particular, proprietary closed source vote-counting software is simply inexcusable.KeywordsVote CountSchulz Method
Certificate VerificationMarginal FunctionVoting ProtocolThese keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.},
    author = {Moses, Lyria and Goré, Rajeev and Levy, Ron and Pattinson, Dirk and Tiwari, Mukesh},
    month = oct,
    year = {2017},
    pages = {66--83},
}

@inproceedings{klein_sel4_2009,
    address = {New York, NY, USA},
    series = {{SOSP} '09},
    title = {{seL4}: formal verification of an {OS} kernel},
    isbn = {978-1-60558-752-3},
    shorttitle = {{seL4}},
    url = {https://doi.org/10.1145/1629575.1629596},
    doi = {10.1145/1629575.1629596},
    abstract = {Complete formal verification is the only known way to guarantee that a system is free of programming errors. We present our experience in performing the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation. seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels.},
    urldate = {2023-06-25},
    booktitle = {Proceedings of the {ACM} {SIGOPS} 22nd symposium on {Operating} systems principles},
    publisher = {Association for Computing Machinery},
    author = {Klein, Gerwin and Elphinstone, Kevin and Heiser, Gernot and Andronick, June and Cock, David and Derrin, Philip and Elkaduwe, Dhammika and Engelhardt, Kai and Kolanski, Rafal and Norrish, Michael and Sewell, Thomas and Tuch, Harvey and Winwood, Simon},
    month = oct,
    year = {2009},
    keywords = {isabelle/hol, l4, microkernel, sel4},
    pages = {207--220},
}

@article{tan_verified_2019,
    title = {The verified {CakeML} compiler backend},
    volume = {29},
    issn = {0956-7968, 1469-7653},
    url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/verified-cakeml-compiler-backend/E43ED3EA740D2DF970067F4E2BB9EF7D},
    doi = {10.1017/S0956796818000229},
    abstract = {The CakeML compiler is, to the best of our knowledge, the most realistic verified compiler for a functional programming language to date. The architecture of the compiler, a sequence of intermediate languages through which high-level features are compiled away incrementally, enables verification of each compilation pass at an appropriate level of semantic detail. Parts of the compiler’s implementation resemble mainstream (unverified) compilers for strict functional languages, and it supports several important features and optimisations. These include efficient curried multi-argument functions, configurable data representations, efficient exceptions, register allocation, and more. The compiler produces machine code for five architectures: x86-64, ARMv6, ARMv8, MIPS-64, and RISC-V. The generated machine code contains the verified runtime system which includes a verified generational copying garbage collector and a verified arbitrary precision arithmetic (bignum) library. In this paper, we present the overall design of the compiler backend, including its 12 intermediate languages. We explain how the semantics and proofs fit together and provide detail on how the compiler has been bootstrapped inside the logic of a theorem prover. The entire development has been carried out within the HOL4 theorem prover.},
    language = {en},
    urldate = {2023-06-26},
    journal = {Journal of Functional Programming},
    author = {Tan, Yong Kiam and Myreen, Magnus O. and Kumar, Ramana and Fox, Anthony and Owens, Scott and Norrish, Michael},
    month = jan,
    year = {2019},
    note = {Publisher: Cambridge University Press},
    pages = {e2},
}

@inproceedings{felty_lean_2015,
    address = {Cham},
    title = {The {Lean} {Theorem} {Prover} ({System} {Description})},
    volume = {9195},
    isbn = {978-3-319-21400-9 978-3-319-21401-6},
    url = {http://link.springer.com/10.1007/978-3-319-21401-6_26},
    doi = {10.1007/978-3-319-21401-6_26},
    abstract = {Lean is a new open source theorem prover being developed at Microsoft Research and Carnegie Mellon University, with a small trusted kernel based on dependent type theory. It aims to bridge the gap between interactive and automated theorem proving, by situating automated tools and methods in a framework that supports user interaction and the construction of fully specified axiomatic proofs. Lean is an ongoing and long-term effort, but it already provides many useful components, integrated development environments, and a rich API which can be used to embed it into other systems. It is currently being used to formalize category theory, homotopy type theory, and abstract algebra. We describe the project goals, system architecture, and main features, and we discuss applications and continuing work.},
    urldate = {2023-06-26},
    publisher = {Springer International Publishing},
    author = {De Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and Van Doorn, Floris and Von Raumer, Jakob},
    editor = {Felty, Amy P. and Middeldorp, Aart},
    year = {2015},
    doi = {10.1007/978-3-319-21401-6_26},
    note = {Book Title: Automated Deduction - CADE-25
Series Title: Lecture Notes in Computer Science},
    pages = {378--388},
}

@incollection{paulin-mohring_introduction_2012,
    address = {Berlin, Heidelberg},
    series = {Lecture {Notes} in {Computer} {Science}},
    title = {Introduction to the {Coq} {Proof}-{Assistant} for {Practical} {Software} {Verification}},
    isbn = {978-3-642-35746-6},
    url = {https://doi.org/10.1007/978-3-642-35746-6_3},
    abstract = {This paper is a tutorial on using the Coq proof-assistant for reasoning on software correctness. It illustrates features of Coq like inductive definitions and proof automation on a few examples including arithmetic, algorithms on functional and imperative lists and cryptographic protocols.},
    language = {en},
    urldate = {2023-06-26},
    booktitle = {Tools for {Practical} {Software} {Verification}: {LASER}, {International} {Summer} {School} 2011, {Elba} {Island}, {Italy}, {Revised} {Tutorial} {Lectures}},
    publisher = {Springer},
    author = {Paulin-Mohring, Christine},
    editor = {Meyer, Bertrand and Nordio, Martin},
    year = {2012},
    doi = {10.1007/978-3-642-35746-6_3},
    keywords = {Elimination Rule, Implicit Argument, Inductive Type, Proof Assistant, Proof Obligation},
    pages = {45--95},
}

@inproceedings{harrison_hol_2009,
    address = {Berlin, Heidelberg},
    series = {Lecture {Notes} in {Computer} {Science}},
    title = {{HOL} {Light}: {An} {Overview}},
    isbn = {978-3-642-03359-9},
    shorttitle = {{HOL} {Light}},
    doi = {10.1007/978-3-642-03359-9_4},
    abstract = {HOL Light is an interactive proof assistant for classical higher-order logic, intended as a clean and simplified version of Mike Gordon’s original HOL system. Theorem provers in this family use a version of ML as both the implementation and interaction language; in HOL Light’s case this is Objective CAML (OCaml). Thanks to its adherence to the so-called ‘LCF approach’, the system can be extended with new inference rules without compromising soundness. While retaining this reliability and programmability from earlier HOL systems, HOL Light is distinguished by its clean and simple design and extremely small logical kernel. Despite this, it provides powerful proof tools and has been applied to some non-trivial tasks in the formalization of mathematics and industrial formal verification.},
    language = {en},
    booktitle = {Theorem {Proving} in {Higher} {Order} {Logics}},
    publisher = {Springer},
    author = {Harrison, John},
    editor = {Berghofer, Stefan and Nipkow, Tobias and Urban, Christian and Wenzel, Makarius},
    year = {2009},
    keywords = {High Order Logic, Inference Rule, Jordan Curve Theorem, Polymorphic Type, Prime Number Theorem},
    pages = {60--66},
}